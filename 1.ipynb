{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " Dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,114\n",
      "Trainable params: 3,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#sequential API\n",
    "model_seq = keras.Sequential(name='model_sequential')\n",
    "model_seq.add(keras.Input(shape =(10,), name= 'Inputlayer'))\n",
    "model_seq.add(keras.layers.Dense(64, 'relu', name = 'Hidden1'))\n",
    "model_seq.add(keras.layers.Dropout(0.2, name = 'Dropout'))\n",
    "model_seq.add(keras.layers.Dense(32, 'relu', name= 'hidden2'))\n",
    "model_seq.add(keras.layers.Dense(10, 'softmax', name = 'output'))\n",
    "model_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 64)                704       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,114\n",
      "Trainable params: 3,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_seq2 = keras.Sequential([\n",
    "    keras.Input(shape =(10,), name= 'Inputlayer'),\n",
    "    keras.layers.Dense(64, 'relu', name = 'Hidden1'),\n",
    "    keras.layers.Dropout(0.2, name = 'Dropout'),\n",
    "    keras.layers.Dense(32, 'relu', name= 'hidden2'),\n",
    "    keras.layers.Dense(10, 'softmax', name = 'output')\n",
    "])\n",
    "model_seq2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_fun\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Inputlayer (InputLayer)     [(None, 10)]              0         \n",
      "                                                                 \n",
      " hidden1 (Dense)             (None, 64)                704       \n",
      "                                                                 \n",
      " Dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,114\n",
      "Trainable params: 3,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Functional API\n",
    "inputs = keras.Input(shape = (10, ), name= 'Inputlayer')\n",
    "hidden1 = keras.layers.Dense(64, 'relu', name = 'hidden1')(inputs)\n",
    "drop_out = keras.layers.Dropout(0.2, name = 'Dropout')(hidden1)\n",
    "hidden2 = keras.layers.Dense(32, 'relu', name='hidden2')(drop_out)\n",
    "outputs = keras.layers.Dense(10, 'softmax', name = 'output')(hidden2)\n",
    "model_fun = keras.Model(inputs = inputs, outputs = outputs, name = 'Model_fun')\n",
    "\n",
    "model_fun.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_sub\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            multiple                  704       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            multiple                  2080      \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,114\n",
      "Trainable params: 3,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Subclassing API\n",
    "\n",
    "class Model_sub(keras.Model):\n",
    "    def __init__(self, hidden1, drop_rate, hidden2, outputs):\n",
    "        super(Model_sub, self).__init__(name='Model_sub')\n",
    "        self.hidden1 = keras.layers.Dense(hidden1,'relu')\n",
    "        self.drop_out = keras.layers.Dropout(drop_rate)\n",
    "        self.hidden2 = keras.layers.Dense(hidden2,'relu')\n",
    "        self.outputs = keras.layers.Dense(outputs, 'softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x=self.hidden1(inputs)\n",
    "        x = self.drop_out(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.outputs(x)\n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "mymodel_sub = Model_sub(64, 0.2, 32, 10)\n",
    "mymodel_sub.build(input_shape=(1,10))\n",
    "mymodel_sub.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.loadtxt('./pima-indians-diabetes.csv', delimiter = ',')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subclassing\n",
    "\n",
    "class DM(keras.Model): #모델상속\n",
    "    def __init__(self, hidden1, drop_out, hidden2, outputs):\n",
    "        super(DM,self).__init__()\n",
    "        self.hidden1 = keras.layers.Dense(hidden1, 'relu')\n",
    "        self.dropout = keras.layers.Dropout(drop_out)\n",
    "        self.hidden2 = keras.layers.Dense(hidden2, 'relu')\n",
    "        self.outputs = keras.layers.Dense(outputs, 'sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.hidden1(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x= self.hidden2(x)\n",
    "        x = self.outputs(x)\n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "dm_model = DM(64, 0.2, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(patience=10)\n",
    "check_point = keras.callbacks.ModelCheckpoint(filepath='./model_save/best_model.h5',\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=True)\n",
    "\n",
    "dm_model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = 'adam',\n",
    "                 metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 25ms/step - loss: 9.8328 - acc: 0.6254 - val_loss: 3.1453 - val_acc: 0.5260\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.5548 - acc: 0.4951 - val_loss: 3.0410 - val_acc: 0.3377\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.3492 - acc: 0.5033 - val_loss: 1.3791 - val_acc: 0.6299\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.5282 - acc: 0.6026 - val_loss: 1.2304 - val_acc: 0.5519\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.2703 - acc: 0.5684 - val_loss: 1.1493 - val_acc: 0.5325\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0782 - acc: 0.5798 - val_loss: 1.0124 - val_acc: 0.6234\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.7529 - acc: 0.5782 - val_loss: 1.0498 - val_acc: 0.5325\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.5679 - acc: 0.5912 - val_loss: 0.8199 - val_acc: 0.6104\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.3958 - acc: 0.6352 - val_loss: 0.8433 - val_acc: 0.5455\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.4047 - acc: 0.6091 - val_loss: 0.7551 - val_acc: 0.5909\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.2112 - acc: 0.6140 - val_loss: 0.8017 - val_acc: 0.5714\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2684 - acc: 0.6221 - val_loss: 0.8021 - val_acc: 0.5130\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.2289 - acc: 0.5928 - val_loss: 0.8459 - val_acc: 0.6429\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.2141 - acc: 0.6026 - val_loss: 0.7609 - val_acc: 0.5779\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1340 - acc: 0.5993 - val_loss: 0.7682 - val_acc: 0.6299\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0764 - acc: 0.6205 - val_loss: 0.7340 - val_acc: 0.5974\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0099 - acc: 0.6173 - val_loss: 0.7401 - val_acc: 0.6104\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9428 - acc: 0.6238 - val_loss: 0.7441 - val_acc: 0.6104\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9222 - acc: 0.6482 - val_loss: 0.7311 - val_acc: 0.5649\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.8319 - acc: 0.6417 - val_loss: 0.7181 - val_acc: 0.5779\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8596 - acc: 0.6254 - val_loss: 0.7434 - val_acc: 0.6299\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9586 - acc: 0.6173 - val_loss: 0.7401 - val_acc: 0.5584\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8863 - acc: 0.6238 - val_loss: 0.7693 - val_acc: 0.6169\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8886 - acc: 0.6596 - val_loss: 0.7379 - val_acc: 0.5974\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.8967 - acc: 0.6482 - val_loss: 0.7282 - val_acc: 0.6039\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.8493 - acc: 0.6450 - val_loss: 0.7640 - val_acc: 0.5909\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8139 - acc: 0.6726 - val_loss: 0.7437 - val_acc: 0.5844\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8385 - acc: 0.6319 - val_loss: 0.7664 - val_acc: 0.6104\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7739 - acc: 0.6580 - val_loss: 0.7509 - val_acc: 0.5714\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7454 - acc: 0.6482 - val_loss: 0.7379 - val_acc: 0.5909\n"
     ]
    }
   ],
   "source": [
    "history = dm_model.fit(X, y, validation_split=0.2,\n",
    "             epochs=100, batch_size=64,\n",
    "             callbacks=[early_stop, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], c = 'r', label = 'Train')\n",
    "plt.plot(history.history['val_loss'], c = 'b', label = 'Validation')\n",
    "plt.legend()\n",
    "plt.grid(alpha = 0.5, linestyle = ':')\n",
    "plt.xlabel = 'epochs'\n",
    "plt.ylabel = 'Loss'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['너 오늘 이뻐 보인다', '나는 오늘 기분이 더러워', '끝내주는데, 좋은 일이 있나봐', '나 좋은 일이 생겼어',\n",
       "       '아 오늘 진짜 짜증나', '환상적인데, 정말 좋은거 같아'], dtype='<U16')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [0], [1], [1], [0], [1]]\n"
     ]
    }
   ],
   "source": [
    "## Sentimental analysis\n",
    "samples = np.array(['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아'])\n",
    "\n",
    "targets =[[1], [0], [1], [1], [0], [1]]\n",
    "\n",
    "display(samples)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('너', 1), ('오늘', 3), ('이뻐', 1), ('보인다', 1), ('나는', 1), ('기분이', 1), ('더러워', 1), ('끝내주는데', 1), ('좋은', 2), ('일이', 2), ('있나봐', 1), ('나', 1), ('생겼어', 1), ('아', 1), ('진짜', 1), ('짜증나', 1), ('환상적인데', 1), ('정말', 1), ('좋은거', 1), ('같아', 1)])\n",
      "{'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "## Tokening\n",
    "tokenizer = keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "print(tokenizer.word_counts)\n",
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n"
     ]
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(samples)\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  5  6]\n",
      " [ 7  1  8  9]\n",
      " [10  2  3 11]\n",
      " [12  2  3 13]\n",
      " [14  1 15 16]\n",
      " [17 18 19 20]]\n"
     ]
    }
   ],
   "source": [
    "input_sequence = np.array(sequence)\n",
    "targets = np.array(targets)\n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 4, 128)            2688      \n",
      "                                                                 \n",
      " tf.math.reduce_mean_1 (TFOp  (None, 128)              0         \n",
      " Lambda)                                                         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 156)               20124     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 157       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,969\n",
      "Trainable params: 22,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) +1\n",
    "emb_size = 128\n",
    "hidden1 = 156\n",
    "hidden2 = 1\n",
    "\n",
    "# sentiment_model = keras.Sequential()\n",
    "# sentiment_model.add(keras.Input(4, )) #4마디로 나눴기 때문에\n",
    "# sentiment_model.add(keras.layers.Embedding(vocab_size, emb_size))\n",
    "# sentiment_model.add(keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis =1)))\n",
    "# sentiment_model.add(keras.layers.Dense(hidden1, 'relu'))\n",
    "# sentiment_model.add(keras.layers.Dense(hidden2, 'sigmoid'))\n",
    "inputs = keras.Input(shape = (4, ))\n",
    "embedding_layer = keras.layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "mean_emb = tf.reduce_mean(embedding_layer, axis = 1)\n",
    "dense1 = keras.layers.Dense(hidden1, 'relu')(mean_emb)\n",
    "outputs = keras.layers.Dense(hidden2, 'sigmoid')(dense1)\n",
    "sentiment_model_fun = keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "sentiment_model_fun.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6594 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.7098e-04 - acc: 1.0000 - val_loss: 0.6624 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.1810e-04 - acc: 1.0000 - val_loss: 0.6627 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.6567e-04 - acc: 1.0000 - val_loss: 0.6668 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.5376e-04 - acc: 1.0000 - val_loss: 0.6689 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.9451e-04 - acc: 1.0000 - val_loss: 0.6711 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.4977e-04 - acc: 1.0000 - val_loss: 0.6709 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.1480e-04 - acc: 1.0000 - val_loss: 0.6704 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 8.7576e-05 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 7.0190e-05 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 5.7465e-05 - acc: 1.0000 - val_loss: 0.6703 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.7936e-05 - acc: 1.0000 - val_loss: 0.6697 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.1724e-05 - acc: 1.0000 - val_loss: 0.6683 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.5835e-05 - acc: 1.0000 - val_loss: 0.6669 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.1202e-05 - acc: 1.0000 - val_loss: 0.6654 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.7879e-05 - acc: 1.0000 - val_loss: 0.6642 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.4861e-05 - acc: 1.0000 - val_loss: 0.6629 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 2.2203e-05 - acc: 1.0000 - val_loss: 0.6616 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0422e-05 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.8350e-05 - acc: 1.0000 - val_loss: 0.6596 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6918e-05 - acc: 1.0000 - val_loss: 0.6586 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.5946e-05 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.4892e-05 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.4159e-05 - acc: 1.0000 - val_loss: 0.6560 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.3561e-05 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1.2946e-05 - acc: 1.0000 - val_loss: 0.6541 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.2333e-05 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1738e-05 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.1177e-05 - acc: 1.0000 - val_loss: 0.6518 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0757e-05 - acc: 1.0000 - val_loss: 0.6512 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.0442e-05 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.0012e-05 - acc: 1.0000 - val_loss: 0.6499 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.7739e-06 - acc: 1.0000 - val_loss: 0.6493 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 9.3359e-06 - acc: 1.0000 - val_loss: 0.6487 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.1376e-06 - acc: 1.0000 - val_loss: 0.6481 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 8.8144e-06 - acc: 1.0000 - val_loss: 0.6477 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 8.5358e-06 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 8.3278e-06 - acc: 1.0000 - val_loss: 0.6468 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 8.1013e-06 - acc: 1.0000 - val_loss: 0.6464 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.8622e-06 - acc: 1.0000 - val_loss: 0.6460 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 7.7178e-06 - acc: 1.0000 - val_loss: 0.6454 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 7.4599e-06 - acc: 1.0000 - val_loss: 0.6450 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 7.3469e-06 - acc: 1.0000 - val_loss: 0.6445 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 7.1560e-06 - acc: 1.0000 - val_loss: 0.6441 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 6.9563e-06 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 6.7443e-06 - acc: 1.0000 - val_loss: 0.6433 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.6088e-06 - acc: 1.0000 - val_loss: 0.6430 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.4793e-06 - acc: 1.0000 - val_loss: 0.6426 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 6.3063e-06 - acc: 1.0000 - val_loss: 0.6424 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.1488e-06 - acc: 1.0000 - val_loss: 0.6420 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 6.0662e-06 - acc: 1.0000 - val_loss: 0.6417 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 5.9120e-06 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.7635e-06 - acc: 1.0000 - val_loss: 0.6411 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.6413e-06 - acc: 1.0000 - val_loss: 0.6409 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.5087e-06 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 5.4389e-06 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.2802e-06 - acc: 1.0000 - val_loss: 0.6400 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.1876e-06 - acc: 1.0000 - val_loss: 0.6398 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 5.0706e-06 - acc: 1.0000 - val_loss: 0.6396 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.9831e-06 - acc: 1.0000 - val_loss: 0.6394 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 4.8843e-06 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 4.7881e-06 - acc: 1.0000 - val_loss: 0.6389 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.7079e-06 - acc: 1.0000 - val_loss: 0.6386 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.6024e-06 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.5272e-06 - acc: 1.0000 - val_loss: 0.6380 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.4285e-06 - acc: 1.0000 - val_loss: 0.6379 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.3572e-06 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.2644e-06 - acc: 1.0000 - val_loss: 0.6374 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.1868e-06 - acc: 1.0000 - val_loss: 0.6373 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.1298e-06 - acc: 1.0000 - val_loss: 0.6370 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 4.0443e-06 - acc: 1.0000 - val_loss: 0.6367 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.9794e-06 - acc: 1.0000 - val_loss: 0.6365 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.8989e-06 - acc: 1.0000 - val_loss: 0.6363 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.8305e-06 - acc: 1.0000 - val_loss: 0.6360 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.7638e-06 - acc: 1.0000 - val_loss: 0.6358 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.7066e-06 - acc: 1.0000 - val_loss: 0.6356 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.6348e-06 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.5736e-06 - acc: 1.0000 - val_loss: 0.6352 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.5080e-06 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.4574e-06 - acc: 1.0000 - val_loss: 0.6349 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.3947e-06 - acc: 1.0000 - val_loss: 0.6348 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.3466e-06 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.2864e-06 - acc: 1.0000 - val_loss: 0.6345 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.2347e-06 - acc: 1.0000 - val_loss: 0.6344 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.1961e-06 - acc: 1.0000 - val_loss: 0.6343 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.1266e-06 - acc: 1.0000 - val_loss: 0.6341 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.0798e-06 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.0451e-06 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.9977e-06 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.9465e-06 - acc: 1.0000 - val_loss: 0.6335 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.9025e-06 - acc: 1.0000 - val_loss: 0.6334 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.8539e-06 - acc: 1.0000 - val_loss: 0.6333 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.8182e-06 - acc: 1.0000 - val_loss: 0.6332 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 2.7715e-06 - acc: 1.0000 - val_loss: 0.6330 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.7372e-06 - acc: 1.0000 - val_loss: 0.6329 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.6974e-06 - acc: 1.0000 - val_loss: 0.6328 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6632e-06 - acc: 1.0000 - val_loss: 0.6326 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.6242e-06 - acc: 1.0000 - val_loss: 0.6324 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5864e-06 - acc: 1.0000 - val_loss: 0.6322 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.5455e-06 - acc: 1.0000 - val_loss: 0.6321 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# sentiment_model.compile(loss= 'binary_crossentropy',\n",
    "#                         optimizer='adam',\n",
    "#                         metrics = ['acc'])\n",
    "\n",
    "# history = sentiment_model.fit(input_sequence, targets, epochs= 100, batch_size= batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subclassing\n",
    "\n",
    "class Sentiment_sub(keras.Model):\n",
    "    def __init__(self, vocab_size, emb_size, hidden, outputs_node):\n",
    "        super(Sentiment_sub, self).__init__()\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, emb_size) \n",
    "        self.dense = keras.layers.Dense(hidden, 'relu')\n",
    "        self.outputs = keras.layers.Dense(outputs_node, 'sigmoid')\n",
    "        \n",
    "    def call(self, input):\n",
    "        x = self.embedding(x)\n",
    "        x = tf.reduce_mean(x, axis = 1)\n",
    "        x = self.dense(x)\n",
    "        x = self.outputs(x)\n",
    "        \n",
    "        return(x)\n",
    "    \n",
    "sentiment_sub = Sentiment_sub(vocab_size, emb_size, 156, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn import datasets  \n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset = sklearn.datasets.load_iris()\n",
    "iris_dataset\n",
    "iris_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# print(iris_datatset['data'])\n",
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])\n",
    "print(iris_dataset['feature_names']) #각각 column이 의미하는바"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal)length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal)length  petal_width  class\n",
       "0           5.1          3.5           1.4          0.2      0\n",
       "1           4.9          3.0           1.4          0.2      0\n",
       "2           4.7          3.2           1.3          0.2      0\n",
       "3           4.6          3.1           1.5          0.2      0\n",
       "4           5.0          3.6           1.4          0.2      0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(iris_dataset['data'])\n",
    "iris['target'] = iris_dataset['target']\n",
    "iris.columns = ['sepal_length','sepal_width','petal)length','petal_width','class']\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_input,test_input,train_target,test_target =train_test_split(\n",
    "    iris_dataset['data'],iris_dataset['target'],\n",
    "    test_size =0.2\n",
    ")\n",
    "\n",
    "print(train_input.shape)\n",
    "print(type(train_input),type(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ss.fit(train_input)\n",
    "train_scaled = ss.transform(train_input)\n",
    "test_scaled = ss.transform(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "{'n_neighbors': 4}\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "params_knn = {'n_neighbors': range(1,10)}\n",
    "gs_knn = GridSearchCV(estimator=knn,\n",
    "                      param_grid=params_knn,\n",
    "                      scoring='accuracy', cv = 5, verbose=1)\n",
    "gs_knn.fit(train_scaled, train_target)\n",
    "\n",
    "print(gs_knn.best_params_)\n",
    "print(gs_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
